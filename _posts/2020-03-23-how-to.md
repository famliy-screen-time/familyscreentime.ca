---
layout: post
title: 'Critical Media Consumption: What Should We Believe?'
date: 2020-03-23T21:28:51.617Z
author: sagetrampleasure
category: blog
---
The internet is full of information, and we are constantly bombarded with social media posts, news articles, and blog entries that make bold claims with significant implications every day. How can we tell which of these claims to believe, and which are more fiction than fact?

# Red Flags

When sifting through your feed, these types of claims should have their truth questioned right off the bat:

## No Source

If someone shares a photo or status on social media that appears to be talking about the results of some sort of study or research, but does not follow it up with a link or reference to where they got this information, there is no reason to believe that the poster didn't just make it up! Posts like these should be either (a) followed up with some hefty researching looking for a reliable source, or (b) IGNORED.

Examples:

![](/assets/uploads/screen-shot-2020-03-23-at-6.27.26-pm.png "No Source")

![](/assets/uploads/21039951_web1_doctor_stock-dr.jpg "No Source")

## Clear Bias

If some sort of claim comes from an individual/group who is clearly biased on a certain topic, chances are that they actively look for and post information about the negative effects of screen time, while completely ignoring or concealing the potential positives. Sources that obviously have a very strong opinion on the matter should be viewed with skepticism, as opposed to more neutral sources.

For example, if you see information on negative impacts of screens posted by a group called "*MOMS AGAINST SCREEN TIME*", or a claim that screen time has zero consequences posted by "*I HEART SCREENS*", it would be a good idea to look further into the claim and get both sides of the issue.

## Weird Website

If a claim appears to be backed up by a link, but instead of the link being to a reputable research journal, news outlet, or government website, it is a personal blog or another type of shady website—**this is a bad sign**. This is an issue because, although the claim is backed up by some type of link, and the website in question may look like a lot of work has gone into the post, it could have been created by anyone—even someone with no reliable knowledge on the issue.

While it is a good idea to go to the website being linked and investigate just how reliable it is, you can often tell when a claim is not-so-solid just by looking at the URL to the website. For example, if a post titled "*Scientists Prove that TV Harms Children's Brains*" links to a source with a URL such as "*newsinformation.truth.myblog.net*", you can already question the truth of this claim without even visiting the website—although you should still take a look.

*If the post in question passes through each of these quality checks, your next (and most important) step is to get to the root of the claim and evaluate the information for yourself.*

# Find the Source

When a post or article claims that "research" or "a study" has found something to be true, it is important to get right to the source - try your best to find the actual article. This can be done through a quick search on Google Scholar (just include the key words in your search), or by following a link to the study if an article has included it. Often, while the whole study may cost money to access, there will usually be a short summary called an "abstract" that you can read for free - check this for...

## Sample Size

One of the most important features of a study is a nice large sample size. This is important because when a study takes a group of children, does research on them, and uses this group to make claims about the entire population of children, it is best that the research group be as large as possible so that it is a meaningful representation of all children. So, if you see a study that researched only 10–20 children, and used their research to make a very bold claim like "*Screen Time Leads to Growth Stunts in Children*", you may not be as inclined to believe that whatever took place for those 10–20 children isn't very likely to take place for the **millions** of other children that the article talks about. When sample sizes get up into the hundreds or even thousands of participants, the research have a lot more weight and are more believable.

## Effect Size

When an article or post makes a claim such as "*Screen Time Leads to Lower IQ*", you should follow up this claim in the study by looking at the actual result that took place (either in the abstract or full study). Here, you may find that while the article made it seem like screen time had a huge effect on IQ, the actual study may have found something much less impressing—slightly higher screen time may have led to .0001% lower IQ—or something much more modest than the article may be claiming.

## Non-Experimental Studies

As mentioned in other blog posts, it is important to remember that *correlation is not causation*. In other words, just because two things are related does NOT mean that one thing caused the other. So, if you see an article claiming that "*screen time causes \_\_\_\_\_\_*", you should find out whether the study in question was an **experimental study** (i.e., that they split people into random groups and had one group watch screens and the other with no screens) or a **correlational study** (i.e., that they measured people's screen time and then measured some other traits). If it is the second kind, they are not able to make the claim that one thing CAUSES the other, only that they happen to be related—and this relationship could go either way, or could even be caused by a completely unrelated variable.

# Takeaways

Hopefully, with these tips for critical media consumption in your toolkit, you will be much more capable of distinguishing false claims from reliable ones. Knowing this information, if you spot that someone on your feed has posted or shared a false claim, you can make a difference by pointing this out and stopping the false information from spreading further!
